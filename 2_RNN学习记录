RNN大致过程与NN差不多,主要的改变是增加了隐藏层.所以主要还是针对RNN的框架进行了学习

1.依照NN的网络,我设置批量大小还是需要Flatten函数进行压平.
2.为了既能够控制批量大小和循环过程,我选择将RBG通道设置为循环点,后两维压平
3.不断更新hidden层

大致明白了批量训练的原理:使用二维矩阵.
在写RNN网络时,我注意到RNN其实更适合具有连续性的样本,但此处是针对图片,我的想法有两个:
将图片按列或行作为循环点,将图片的RBG通道作为循环点.经过考虑运行时间,我选择了后者.