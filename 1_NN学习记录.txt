一.定义NN网络
1.了解到nn.Linear构造神经元，（in，out）in指输入的特征数，out指输出特征数
2.由此可知，为构造128与256的二层结构，我给出了3次Linear操作，in->hidden1->hidden2->out
3.使用了torch.relu函数激活线性变换。根据学习我知道了，进过线性变换后若不进行非线性变换，那么若干个形式上的神经元在数学上就是一个神经元，不算多层结构。


二.解析测试集
1.此前未曾了解过数据集是怎样给模型训练的，于是在网上查找了一些教程，copy了解析数据集的代码。
2.开始我是将mnist-test\0丢给模型，报了错，后面发现是将所有文件夹一并丢给模型，每种类型属于主文件夹下的一个类型文件夹。

三.训练模型
1.学习了enumerate函数，记录了学习进度，同时提取图片及标签。
2.了解了反向传播在深度学习的重要性（类似于动态规划，减少计算量），能够快速更新参数。

四.测试模型/指标计算
1.测试过程和训练过程差不多，主要还是指标计算函数。这里准确率较高我认为是在预测1<->1,1<->2,2<->1的时候，3、4、5······都会加TN导致TN比TP大很多影响较大的缘故，也许是多分类的指标计算都会有这个问题

五.一些其他问题
1.在设置批量大小时，报了一个Mat维度不同导致不能传播的问题，经过调整数据和搜索，我认为是传入的是一个4维的Mat，然后默认把前三维大小相乘作为了批量大小，最后一维作为了in。经过了解，我使用了FLatten函数，将Mat后三维压平，也就是说，前一维作为样本个数，后三维是每个样本的特征。
